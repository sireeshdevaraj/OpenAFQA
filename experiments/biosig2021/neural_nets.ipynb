{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bba276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT CODE \n",
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from IPython import display\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def cv2_imshow(a):\n",
    "  \"\"\"A replacement for cv2.imshow() for use in Jupyter notebooks.\n",
    "  Args:\n",
    "    a : np.ndarray. shape (N, M) or (N, M, 1) is an NxM grayscale image. shape\n",
    "      (N, M, 3) is an NxM BGR color image. shape (N, M, 4) is an NxM BGRA color\n",
    "      image.\n",
    "  \"\"\"\n",
    "  a = a.clip(0, 255).astype('uint8')\n",
    "  # cv2 stores colors as BGR; convert to RGB\n",
    "  if a.ndim == 3:\n",
    "    if a.shape[2] == 4:\n",
    "      a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
    "    else:\n",
    "      a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "  display.display(Image.fromarray(a))\n",
    "\n",
    "def load_data(location, labels, metric):\n",
    "    fv_list = os.listdir(location)\n",
    "    fv_nb = len(fv_list)\n",
    "\n",
    "    with open(location + fv_list[0], \"rb\") as handle: \n",
    "        fv0 = pickle.load(handle)\n",
    "\n",
    "    with open(labels, \"rb\") as handle: \n",
    "        labels = pickle.load(handle)\n",
    "\n",
    "    print(\"Number of vectors: \" + str(fv_nb) + \" of length \" + str(len(fv0)))\n",
    "\n",
    "    data_x = np.zeros(shape=(fv_nb, len(fv0)))\n",
    "    data_y = np.zeros(shape=(fv_nb,))\n",
    "\n",
    "    for i, fv_filename in enumerate(fv_list): \n",
    "        with open(location + fv_filename, \"rb\") as handle: \n",
    "            fv = pickle.load(handle)\n",
    "        \n",
    "        fid = fv_filename.split(\".\")[0]\n",
    "\n",
    "        data_y[i] = 0\n",
    "        if metric in labels[fid]: \n",
    "            data_y[i] = labels[fid][metric] \n",
    "\n",
    "        data_x[i] = fv\n",
    "\n",
    "    return data_x, data_y, fv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e01227f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors: 12000 of length 192\n",
      "Number of vectors: 1200 of length 192\n"
     ]
    }
   ],
   "source": [
    "DATA_FOLDER = \"D:\\\\NIST datasets\\\\feature_vector_dataset\\\\\"\n",
    "\n",
    "LABELS = DATA_FOLDER + \"qualities_v2.pkl\"\n",
    "metric = \"nfiq2\"\n",
    "\n",
    "train_x, train_y, train_names = load_data(DATA_FOLDER + \"train/\", LABELS, metric)\n",
    "test_x, test_y, test_names = load_data(DATA_FOLDER + \"test/\", LABELS, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f938bdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 26437.83219675\n",
      "Iteration 2, loss = 225.13156772\n",
      "Iteration 3, loss = 101.89072367\n",
      "Iteration 4, loss = 64.95964125\n",
      "Iteration 5, loss = 52.67105414\n",
      "Iteration 6, loss = 45.81471989\n",
      "Iteration 7, loss = 41.04711390\n",
      "Iteration 8, loss = 38.52202595\n",
      "Iteration 9, loss = 36.95691145\n",
      "Iteration 10, loss = 35.76409176\n",
      "Iteration 11, loss = 35.34854960\n",
      "Iteration 12, loss = 34.86419530\n",
      "Iteration 13, loss = 34.29140994\n",
      "Iteration 14, loss = 34.66523103\n",
      "Iteration 15, loss = 32.73559394\n",
      "Iteration 16, loss = 32.54549698\n",
      "Iteration 17, loss = 32.45623406\n",
      "Iteration 18, loss = 32.13887360\n",
      "Iteration 19, loss = 32.70223988\n",
      "Iteration 20, loss = 31.25108522\n",
      "Iteration 21, loss = 31.02934685\n",
      "Iteration 22, loss = 30.94360868\n",
      "Iteration 23, loss = 30.79683477\n",
      "Iteration 24, loss = 30.76941389\n",
      "Iteration 25, loss = 30.43099183\n",
      "Iteration 26, loss = 30.09478630\n",
      "Iteration 27, loss = 29.44487339\n",
      "Iteration 28, loss = 29.44848969\n",
      "Iteration 29, loss = 29.95462505\n",
      "Iteration 30, loss = 28.89720248\n",
      "Iteration 31, loss = 28.51422172\n",
      "Iteration 32, loss = 28.32080740\n",
      "Iteration 33, loss = 28.27641161\n",
      "Iteration 34, loss = 28.05952601\n",
      "Iteration 35, loss = 27.58402083\n",
      "Iteration 36, loss = 27.78668109\n",
      "Iteration 37, loss = 27.49702296\n",
      "Iteration 38, loss = 27.53295620\n",
      "Iteration 39, loss = 27.93603794\n",
      "Iteration 40, loss = 27.06470571\n",
      "Iteration 41, loss = 27.09871700\n",
      "Iteration 42, loss = 27.03731647\n",
      "Iteration 43, loss = 28.85867560\n",
      "Iteration 44, loss = 27.73987676\n",
      "Iteration 45, loss = 26.95639642\n",
      "Iteration 46, loss = 26.80634589\n",
      "Iteration 47, loss = 26.26539551\n",
      "Iteration 48, loss = 26.16375628\n",
      "Iteration 49, loss = 25.74506014\n",
      "Iteration 50, loss = 27.29089905\n",
      "Iteration 51, loss = 26.02445310\n",
      "Iteration 52, loss = 25.54062436\n",
      "Iteration 53, loss = 25.67832033\n",
      "Iteration 54, loss = 26.69880399\n",
      "Iteration 55, loss = 25.77285303\n",
      "Iteration 56, loss = 25.90626956\n",
      "Iteration 57, loss = 26.95700948\n",
      "Iteration 58, loss = 25.15919461\n",
      "Iteration 59, loss = 24.18117760\n",
      "Iteration 60, loss = 24.39928801\n",
      "Iteration 61, loss = 23.20226503\n",
      "Iteration 62, loss = 24.51712703\n",
      "Iteration 63, loss = 24.93786767\n",
      "Iteration 64, loss = 22.44366085\n",
      "Iteration 65, loss = 22.57023807\n",
      "Iteration 66, loss = 25.11778648\n",
      "Iteration 67, loss = 23.35431706\n",
      "Iteration 68, loss = 22.98338075\n",
      "Iteration 69, loss = 21.68680189\n",
      "Iteration 70, loss = 22.67922243\n",
      "Iteration 71, loss = 21.88250351\n",
      "Iteration 72, loss = 21.82892445\n",
      "Iteration 73, loss = 22.15228190\n",
      "Iteration 74, loss = 23.60065876\n",
      "Iteration 75, loss = 23.41444939\n",
      "Iteration 76, loss = 22.05723347\n",
      "Iteration 77, loss = 21.74141923\n",
      "Iteration 78, loss = 21.23404127\n",
      "Iteration 79, loss = 24.25317031\n",
      "Iteration 80, loss = 24.91954374\n",
      "Iteration 81, loss = 21.10088136\n",
      "Iteration 82, loss = 21.26028413\n",
      "Iteration 83, loss = 22.41803233\n",
      "Iteration 84, loss = 24.50463630\n",
      "Iteration 85, loss = 23.53309780\n",
      "Iteration 86, loss = 22.85309781\n",
      "Iteration 87, loss = 21.15060139\n",
      "Iteration 88, loss = 23.82570269\n",
      "Iteration 89, loss = 21.93368999\n",
      "Iteration 90, loss = 21.73047345\n",
      "Iteration 91, loss = 21.39453480\n",
      "Iteration 92, loss = 24.24552570\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "train MSE 40.141632072329834\n",
      "test MSE 59.62798386956022\n",
      "train MAE 4.899500441061534\n",
      "test MAE 5.702435535807826\n",
      "train R2 0.8446161343909244\n",
      "test R2 0.5822061971010253\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "regr = MLPRegressor(verbose=True, alpha=0.0001, random_state=2, max_iter=500, solver=\"adam\")\n",
    "regr.fit(train_x, train_y)\n",
    "\n",
    "predictions = np.clip(regr.predict(test_x), 0, 100)\n",
    "train_predictions = np.clip(regr.predict(train_x), 0, 100)\n",
    "\n",
    "print(\"train MSE\", mean_squared_error(train_y, train_predictions))\n",
    "print(\"test MSE\", mean_squared_error(test_y, predictions))\n",
    "\n",
    "print(\"train MAE\", mean_absolute_error(train_y, train_predictions))\n",
    "print(\"test MAE\", mean_absolute_error(test_y, predictions))\n",
    "\n",
    "print(\"train R2\", r2_score(train_y, train_predictions))\n",
    "print(\"test R2\", r2_score(test_y, predictions))\n",
    "\n",
    "with open(\"nn_model_nfq.pkl\", \"wb\") as handle: \n",
    "    pickle.dump(regr, handle)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:qa] *",
   "language": "python",
   "name": "conda-env-qa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}